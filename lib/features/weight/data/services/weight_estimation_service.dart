import 'dart:io';
import 'dart:math' as math;

import 'package:flutter/services.dart' show rootBundle;
import 'package:image/image.dart' as img;
import 'package:riverpod_annotation/riverpod_annotation.dart';
import 'package:tflite_flutter/tflite_flutter.dart';

import '../../../../core/constants/app_constants.dart';
import '../../../../core/utils/logger.dart';
import '../../../../services/ml/tflite_service.dart';
import '../models/weight_estimation_model.dart';

part 'weight_estimation_service.g.dart';

/// Service that handles TFLite model inference for pig weight estimation.
///
/// **Lifecycle:**
/// 1. Call [initialize] once at app startup (loads labels + inspects model).
/// 2. Call [estimateFromImage] for each captured photo (top or side view).
/// 3. Call [calculateBestEstimate] after both views are processed.
///
class WeightEstimationService {
  WeightEstimationService({required TfliteService tfliteService})
    : _tfliteService = tfliteService;

  final TfliteService _tfliteService;

  /// Weight labels in model output order (index â†’ label string).
  List<String> _labels = [];

  /// Parsed numeric weights corresponding to [_labels].
  List<double> _weights = [];

  /// Model input dimensions discovered at load time.
  int _inputHeight = 224;
  int _inputWidth = 224;
  int _inputChannels = 3;

  /// Whether the model expects float32 (normalized 0â€“1) or uint8 (0â€“255).
  bool _isFloat32Input = true;

  /// Number of output classes.
  int _numClasses = 0;

  /// How many top predictions to retain in the result.
  static const int topN = 5;

  bool _isInitialized = false;
  bool get isInitialized => _isInitialized;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Initialization
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Load labels from the asset file and inspect the model's tensor shapes.
  ///
  /// Must be called once before any inference calls.
  Future<void> initialize() async {
    if (_isInitialized) return;

    await _loadLabels();
    await _inspectModelShape();
    _isInitialized = true;

    AppLogger.info(
      'WeightEstimationService initialized â€” '
      '${_labels.length} classes, '
      'input: ${_inputHeight}x$_inputWidth x$_inputChannels '
      '(${_isFloat32Input ? "float32" : "uint8"})',
      tag: 'WEIGHT',
    );
  }

  /// Parse the labels file. Each line is a weight class (e.g., "85kg").
  /// Order must be preserved â€” line index matches model output index.
  Future<void> _loadLabels() async {
    final raw = await rootBundle.loadString(AppConstants.weightLabelsAsset);
    _labels = raw
        .split('\n')
        .map((line) => line.trim())
        .where((line) => line.isNotEmpty)
        .toList();

    _weights = _labels.map(_parseWeight).toList();
    _numClasses = _labels.length;

    AppLogger.debug('Loaded $_numClasses weight labels', tag: 'WEIGHT');
  }

  /// Extract numeric weight from a label like "85kg".
  double _parseWeight(String label) {
    return double.parse(label.replaceAll('kg', ''));
  }

  /// Inspect the loaded model's input/output tensors to determine
  /// the expected image dimensions and data type.
  Future<void> _inspectModelShape() async {
    if (!_tfliteService.isModelLoaded) {
      await _tfliteService.loadModel();
    }

    // Access the interpreter to read tensor metadata.
    // TfliteService exposes the interpreter indirectly via runInference,
    // but we need shape info. We'll read from the model asset directly.
    try {
      final interpreter = await Interpreter.fromAsset(
        AppConstants.weightModelAsset,
      );

      final inputTensor = interpreter.getInputTensor(0);
      final inputShape = inputTensor.shape; // e.g., [1, 224, 224, 3]
      final inputType = inputTensor.type;

      if (inputShape.length == 4) {
        _inputHeight = inputShape[1];
        _inputWidth = inputShape[2];
        _inputChannels = inputShape[3];
      }
      _isFloat32Input = inputType == TensorType.float32;

      final outputTensor = interpreter.getOutputTensor(0);
      final outputShape = outputTensor.shape; // e.g., [1, 95]
      if (outputShape.length >= 2) {
        _numClasses = outputShape[1];
      }

      interpreter.close();

      AppLogger.debug(
        'Model shape â€” input: $inputShape ($inputType), '
        'output: $outputShape ($_numClasses classes)',
        tag: 'WEIGHT',
      );
    } catch (e) {
      AppLogger.warn(
        'Could not inspect model shape, using defaults: $e',
        tag: 'WEIGHT',
      );
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Inference
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Run inference on a single image file.
  ///
  /// [imagePath] â€” absolute path to the image file on device.
  /// [viewType] â€” `'top'` or `'side'` (for labelling the result).
  ///
  /// Returns a [ViewEstimationResult] with the predicted weight,
  /// confidence, ambiguity flag, and top-N predictions.
  Future<ViewEstimationResult> estimateFromImage({
    required String imagePath,
    required String viewType,
  }) async {
    if (!_isInitialized) {
      throw StateError(
        'WeightEstimationService not initialized. Call initialize() first.',
      );
    }

    AppLogger.debug(
      'Running inference on $viewType view: $imagePath',
      tag: 'WEIGHT',
    );

    // 1. Load and preprocess the image.
    final input = await _preprocessImage(imagePath);

    // 2. Prepare output buffer.
    final output = List.filled(_numClasses, 0.0).reshape([1, _numClasses]);

    // 3. Run inference.
    _tfliteService.runInference(input, output);

    // 4. Apply softmax to convert raw logits â†’ probabilities.
    //    The model outputs raw logits (NormalizedMobileNetV2 has no final
    //    softmax layer), so we must convert them here before computing
    //    confidence scores. Without this, "confidence" values would be
    //    arbitrary real numbers rather than the [0, 1] range expected.
    final logits = (output[0] as List<dynamic>).cast<double>();
    final probabilities = _softmax(logits);

    // 5. Build sorted predictions.
    final predictions = _buildPredictions(probabilities);

    final topPrediction = predictions.first;

    AppLogger.info(
      '$viewType view â†’ ${topPrediction.label} '
      '(${(topPrediction.confidence * 100).toStringAsFixed(1)}%)',
      tag: 'WEIGHT',
    );

    // ğŸ› DEBUG â€” dump top-5 predictions so we can verify model output
    final top5 = predictions.take(topN).toList();
    for (var i = 0; i < top5.length; i++) {
      final p = top5[i];
      AppLogger.debug(
        '  #${i + 1}  ${p.label.padRight(6)}  ${(p.confidence * 100).toStringAsFixed(2)}%',
        tag: 'WEIGHT_DEBUG',
      );
    }

    return ViewEstimationResult(
      weightKg: topPrediction.weightKg,
      confidence: topPrediction.confidence,
      isAmbiguous: false,
      imagePath: imagePath,
      viewType: viewType,
      allPredictions: predictions.take(topN).toList(),
    );
  }

  /// Compare both views and pick the one with higher confidence.
  ///
  /// Returns a [WeightEstimationModel] with the final estimate.
  /// Call this after both views have been processed individually.
  WeightEstimationModel calculateBestEstimate({
    required ViewEstimationResult topViewResult,
    required ViewEstimationResult sideViewResult,
  }) {
    final bestIsTop = topViewResult.confidence >= sideViewResult.confidence;

    final winner = bestIsTop ? topViewResult : sideViewResult;

    AppLogger.info(
      'Best estimate: ${winner.weightKg}kg from ${winner.viewType} view '
      '(${(winner.confidence * 100).toStringAsFixed(1)}%)',
      tag: 'WEIGHT',
    );

    return WeightEstimationModel(
      estimatedWeightKg: winner.weightKg,
      confidence: winner.confidence,
      sourceView: winner.viewType,
      imagePath: winner.imagePath,
      topViewResult: topViewResult,
      sideViewResult: sideViewResult,
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Image Preprocessing
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Load an image from disk, resize to model dimensions, normalise,
  /// and return the input tensor.
  Future<List<List<List<List<double>>>>> _preprocessImage(
    String imagePath,
  ) async {
    final bytes = await File(imagePath).readAsBytes();
    var image = img.decodeImage(bytes);

    if (image == null) {
      throw ArgumentError('Could not decode image at $imagePath');
    }

    // Handle EXIF orientation.
    image = img.bakeOrientation(image);

    // Resize to model input dimensions.
    image = img.copyResize(
      image,
      width: _inputWidth,
      height: _inputHeight,
      interpolation: img.Interpolation.linear,
    );

    // Build the 4D input tensor [1, height, width, channels].
    final input = List.generate(
      1,
      (_) => List.generate(
        _inputHeight,
        (y) => List.generate(_inputWidth, (x) {
          final pixel = image!.getPixel(x, y);

          if (_isFloat32Input) {
            // Normalize to 0.0 â€“ 1.0
            return [pixel.r / 255.0, pixel.g / 255.0, pixel.b / 255.0];
          } else {
            return [pixel.r.toDouble(), pixel.g.toDouble(), pixel.b.toDouble()];
          }
        }),
      ),
    );

    return input;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // Prediction Parsing
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Convert raw logits to a probability distribution via softmax.
  ///
  /// Uses the numerically stable max-subtraction form:
  ///   softmax(x_i) = exp(x_i âˆ’ max) / Î£ exp(x_j âˆ’ max)
  ///
  /// The model (NormalizedMobileNetV2) has no final activation layer and
  /// outputs raw logits, so this must be applied before reading confidence.
  List<double> _softmax(List<double> logits) {
    if (logits.isEmpty) return [];
    final maxLogit = logits.reduce(math.max);
    final exps = logits.map((v) => math.exp(v - maxLogit)).toList();
    final sumExp = exps.reduce((a, b) => a + b);
    return exps.map((v) => v / sumExp).toList();
  }

  /// Build a sorted list of [PredictionClass] from raw output probabilities.
  List<PredictionClass> _buildPredictions(List<double> probabilities) {
    final predictions = <PredictionClass>[];

    for (var i = 0; i < probabilities.length && i < _numClasses; i++) {
      predictions.add(
        PredictionClass(
          weightKg: _weights[i],
          confidence: probabilities[i],
          label: _labels[i],
        ),
      );
    }

    // Sort descending by confidence.
    predictions.sort((a, b) => b.confidence.compareTo(a.confidence));
    return predictions;
  }
}

/// Singleton provider for [WeightEstimationService].
///
/// Initialisation must happen before first use. The [weightFormProvider]
/// handles calling [initialize] during its build phase.
@Riverpod(keepAlive: true)
WeightEstimationService weightEstimationService(Ref ref) {
  return WeightEstimationService(
    tfliteService: ref.watch(tfliteServiceProvider),
  );
}
